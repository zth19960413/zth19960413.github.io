[{"title":"学习笔记之网络部分","url":"/2019/05/28/学习笔记之网络部分/","content":"\n**在进入大三阶段，马上面临大四即将到来的实习，在此时期为了能找到一个好的工作，对大学所学的知识，依据慕课网《剑指Java面试-Offer直通车》的讲解体系，进行了一个系统化的总结**\n\n~~接下来进入第一章网络部分的讲解~~\n\n# TCP\n----\n## OSI开放式互联参考模型\n* 物理层：机械、电子、定时接口通信商的原始比特流传输，这里就是发送比特流最基本的数据，就是0101二进制数据，最根本的就是电流的强弱来进行传输，比如高电平是1低电平是0。\n\n* 数据链路层：物理寻址、同时将原始比特流转变为逻辑传输线路。这里主要是对数据进行格式化，对数据进行一层封装，加了一层的校验。\n\n* 网络层：控制子网的运行，如逻辑地址、分组传输、路由的选择。把网络地址翻译成对应的物理地址，我的理解就是可以寻址。给这段代码在网络上给了一个表示，目的地址和本地地址应该在这里面。\n\n* 传输层：接收上一层的数据，在必要的时候吧数据进行分割，并将这些数据交给网络层，且保证这些数据段有效到达对端。这一层主要考虑的是传输质量的问题，对于接收方能接受的数据的程度来对数据进行处理。对数据包可以进行强制分割，以至于在传输的过程中不会造成大量丢失，使网络传输的接受范围之内。\n\n* 会话层：不同机器上的据用之间建立和管理回话。\n\n* 表示层：信息的语法语义以及它们的关联，如加密解密、转换翻译、压缩解压缩。主要一个功能就是解决不同系统之间的通信，比如我是windows和一个linux系统的之间通信就是靠表示层来进行转换翻译和解压缩的。\n\n* 应用层：这里比较关注的就是HTTP协议\n\n>**OSI并不是一个标准，而是一个在制定标准时所使用的概念性框架。**\n\n![先自上而下，后自下而上处理数据头部](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528201225.png)\n\n### TCP/IP协议\n\n![OSI的“实现”：TCP/IP](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528201302.png)\n\n**传输控制协议TCP简介**\n\n1. 面向连接的、可靠的、基于字节流的传输层通信协议\n\n2. 将应用层的数据流分割成报文段并发送给目标节点的TCP层\n\n3. 数据包都有序号，对方收到则发送ACK确认，未收到则重新传\n\n4. 使用校验和来检验数据在传输过程中是否有误  TCP Flags\n\t\n**TCP Flags**\n\n* URG：紧急指针标志\n\n* **ACK：确认序号标志（1表示确认号有效，0报文中不含确认信息）**\n\n* PSH：push标志（相当于优先处理，不在缓冲区排队）\n\n* RST：重置连接标志\n\n* **SYN：同步序号，用于建立连接过程 **\n\n* **FIN：finish标志用于释放连接（1没有数据发送了，0还有数据）**\n## 三次握手\n\n>**TCP是全双工的通信，三次握手是为了建立连接**\n\n![ 流程图 ](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528201519.png)\n\nSeq（Sequence Number）是初始信号正整数值\n\n在第一次握手接收端返回的ack为x+1，因为在之前seq消耗了一个x就要+1，seq是为缓存初始一个序列号y\n\n同理在第三次握手的时候发送端的seq为x+1，ack为y+1\n\n**在TCP/IP协议中，TCP协议提供可靠的链接服务，采用三次握手建立一个链接**\n\n>**第一次握手：建立连接时，客户端发送SYN包（syn=j）到服务器，并进入SYN_SEND状态，等待服务器确认；**\n\n>**第二次握手：服务器收到SYN包，必须确认客户的SYN（ackj+1），同时自己也发送一个SYN包（syn=k）,即SYN+ACK包，此时服务器进入SYN_RECV状态；**\n\n>**第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK（ack=k+1）,此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手，进行数据的传输。**\n\n### TCP报文头\n\n![TCP报文头](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528202707.png)\n\n这里我对TCP的报文头不做过多的说明，在网上有好多博客写了这方面的知识比较全面\n\n如果对这里特别感兴趣可以下载Wireshark的抓包工具。\n\n![Wireshark](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528203306.png)\n\n我打开这个软件，随便浏览网上一个网址，在上面地址栏输入正则表达式，然后对一个固定IP36.104.142.35进行抓包，就可以查看TCP的链接状态，以及报文内容格式\n\n![抓包截图](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528203756.png)\n### SYN  Flood的防护\n\n**在第一次握手的时候会有超时的隐患**\n\n**问题起因的分析**\n\n* Server（服务器端）收到Clinent（客户端）的SYN，恢复SYN-ACK的时候，我们的Clinent就掉线了，Server未收到ACK的确认，那么这个连接就会处于一个中间的状态，即没有成功也没有失败\n\n* Server（服务器端）不断重连直至超时，Linux默认重试次数为5次，每次重连的时间从1秒开始，每次都翻倍，一共的等待1+2+4+6+16+32=63秒（这里可以理解为一个加号为一次重连机会）才断开连接\n\n**在这个时候有可能会遭受到SYN Flood攻击的风险，攻击程序会给服务器发送一个SYN的报文，发了之后它就下线了需要服务器默认等63秒才会断开这个连接，这样攻击者就会把服务器的SYN连接的队列耗尽，将正常的连接请求不能处理。**\n\n**针对SYN Flood的防护措施**\n\n* 在Linux下呢，SYN队列满了后，通过源地址端口和目标地址端口和时间戳打造出特别的seq就是tcp_syncookies参数回发SYN Cookie，如果是攻击者是不会有响应的\n\n* 若为正常连接则Clinet会回发SYN Cookie，利用Cookie来直接建立连接。\n\n**建立连接后，Client出现了故障怎么办**\n\nTCP还设有保活机制\n\n* 在一段时间，连接处于非活动状态，开启保护功能的一段向对方发送保活探测报文，如果发送端没有收到响应报文，那么经过体检经过设置好的保活时间内则继续发送知道连接为止\n\n* 尝试次数达到保活探测数仍未收到响应则中断连接\n\n### 为什么要进行三次握手\n\n**为了初始化Sequence Number的初始值，通信的双方通知自己的初始化的SN的值，作为以后通信的信号，不会因为网络上的传输问题而乱序，TCP用这个序号来拼接这个序号。**\n\n## 四次挥手\n![流程图](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190528211446.png)\n\nTCP采用四次挥手来释放连接\n\n>**第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态；**\n\n>**第二次挥手：server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态；**\n\n>**第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态；**\n\n>**第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。**\n\n### TIME_WAIT\n\n**为什么会有TIME_WAIT的状态？**\n\n* 确保有足够的时间让对端收到ACK的包，如果被动关闭的一方没有收到ACK，就会触发被动端重发Finish。\n\n* 有足够的时间，让连接不会跟后面的链接混在一起，因为有些路由器会缓存IP数据包，如果连接被重用了那么这些延迟收到的包呢，就有可能会跟新连接的包混在一起。\n\n### 为什么要进行四次挥手\n\n因为是全双工的，发送方和接收方都需要FIN报文和ACK报文。其实只需要两次挥手即可，只不过有一方是被动的所以看上去就成了所谓的四次挥手\n### CLOSE_WAIT\n\n服务器出现大量CLOSE_WAIT状态的原因\n\n对方关闭socket连接，我方忙于读或者写，没有及时的关闭连接，遇到这种情况多数是程序有BUG，还有可能是线程的配置不合理。\n\n解决方法\n\n* 检查代码\n\n* 检查配置\n\n## 滑动窗口\n\n**首先了解RTT和RTO是什么**\n\n* RTT：发送一个数据包到收到对应的ADC，所花费的时间\n\n* RTO：重传时间间隔\n\n**前面我们了解到TCP会将数据拆分成段进行发送，出于效率和传输速度的考虑，我们不可能等一段数据去发送，等到上一段数据被确认之后再发送下一段数据，这个效率是非常低的，我们是要实现对数据的批量发送，TCP必须要解决可靠传输以及包乱序的问题，所以TCP需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。**\n\nTCP使用滑动窗口做流量控制与乱序重排，两个作用\n\n* 保证TCP的可靠性\n\n* 保证TCP的流控特性\n\n**前面在TCP的报文头中有一个字段是WINDOWS，就是第四行第二的字段就是滑动窗口的字段。用于接收方通知发送方自己，还有多少缓冲区可以接收数据，发送方根据接收方的处理能力来发送数据。不会导致接收方处理不过来，这就是流量控制。**\n\n![滑动窗口](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529162421.png)\n\n根据上面的图可以清晰的理解到底什么是滑动窗口\n\n## TCP和UDP的区别\n\n![UDP报文](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529162540.png)\n\n上图是UDP报文的结构，相对于TCP少了很多。\n\n**UDP的特点：**\n\n* 面向非连接，传送速度是根据程序生成的速度所影响。\n\n* 不维护连接状态，服务端支持同时向多个客户端传输相同的消息\n\n* 数据包报头只有8个字节，额外开销小\n\n* 吞吐量只受限于数据生成速率、传输速率以及机器性能\n\n* 尽最大努力交付，不保证可靠交付，不需要维持复杂的链接状态表。\n\n* 面向报文，不对应用程序提交的报文信息进行拆分或者合并\n\n**TCP和UDP的区别结论**\n\n* 面向连接 VS 无连接\n\n* TCP是可靠的\n\n* TCP是有序的\n\n* TCP的速度比UDP的速度慢\n\n* UDP是轻量级的\n\n# HTTP\n\n**超文本传输协议HTTP主要特点：**\n\n* 支持客户/服务器模式\n\n* 简单快速（只需要传送请求方法和路径，get和post）\n\n* 灵活（传输任意类型的数据对象）\n\n* 无连接 \n\n* 无状态（对于事务的处理没有记忆能力）\n\n## 请求结构\n\n![HTTP的请求结构](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529163317.png)\n\n## 响应结构\n\n![HTTP的响应结构](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529163451.png)\n\n## 请求/响应步骤\n\n1. 客户端连接到Web服务器\n\n2. 发送HTTP请求\n\n3. 服务器接收请求并返回HTTP响应\n\n4. 释放连接TCP连接\n\n5. 客户端浏览器解析HTML内容\n\n## 浏览器输入URL经历的流程\n\n1. DNS解析，先接续本地，然后路由器，然后上级域名，然后顶级域名这样如果查到了不再继续向上查询。\n\n2. TCP连接\n\n3. 发送HTTP请求\n\n4. 服务器处理请求并返回HTTP报文\n\n5. 浏览器解析渲染页面，就是所谓的加载界面\n\n6. 连接结束\n\n## 状态码\n\n**这里的状态码由于太多了，我进行了一个归类根据第一个数字进行归类如下**\n\n* 1XX：指示信息--表示请求已经接受，继续处理\n\n* 2XX：成功--表示请求已被成功接受、理解、接受\n\n* 3XX：重定向--要完成请求必须进行跟进一步的操作\n\n* 4XX：客户端错误--请求有语法错误或请求无法实现\n\n* 5XX：服务器端错误--服务器未能实现合法的请求\n\n**根据我所遇到的有如下经常看到的进行了总结**\n\n* 200 OK：正常返回信息\n\n* 400 Bad Request：客户端请求有语法错误，不能被服务器所理解\n\n* 401 Unauthorized：请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用\n\n* 403 Forbidden：服务器收到请求，但是拒绝提供服务\n\n* 404 Not Found：请求资源不存在或者输入了错误的URL\n\n* 500 Internal Server Error：服务器发生不可预期的错误\n\n* 503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常\n\n## GET和POST的区别\n**从三个层面来解答**\n\n* 从Http报文的层面上来说，get请求的信息可以放在URL中，有些浏览器对于URL对于长度有限制，那么get的请求可能会丢失信息。对于大量的来说只能用POST\n\n* 从数据库的层面上来说，get请求是对数据库进行了操作，操作和结果是一致的，具有幂等性。对数据库的操作，但是没有改变数据库中的数据，get请求是做查询操作，所以不会改变数据库，所以也具有安全性 。\n\n* 其他层面：GET可以被缓存，可以存在浏览器的缓存中\n## Cookie和Session的区别\n\n**Cookie**\n\n是由服务器发给客户端的特殊信息，以文本的形式存放在客户端\n\n客户端再次请求的时候，会把Cookie回发\n\n服务器接收到后，会解析Cookie生成与客户端相对应的内容  \n\n**Cookie的设置以及发送过程**\n\n![Cookie的设置以及发送过程](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529165109.png)\n\n**Session**\n\n服务器的机制，在服务器上保存的信息\n\n解析客户端请求并操作session id，按需要保存状态信息\n\nSession实现方式有两种：\n\n* 用Cookie来实现\n\n![](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529165237.png)\n\n* 使用URL回写来实现   \n\n**它们之间的区别**\n\n* Cookie数据存放在客户的浏览器上，Session数据放在服务器上\n\n* Session相对于Cookie更安全\n\n* 若考虑减轻服务器的负担，应当使用Cooke\n\n## HTTP和HTTPS的区别\n\n![HTTP和HTTPS的区别](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529165428.png)\n\n图中的SLL（Security Sockets Layer，安全套接层）\n\n* 为网络通信提供安全及数据完整性的一种安全协议\n\n* 是操作系统对外的API，SSL3.0后更名为TLS\n\n* 采用身份验证和数据加密保证网络通信的安全和数据的完整性\n\nHTTPS数据传输流程\n\n* 浏览器将支持的加密算法信息发送给服务器\n\n* 服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器\n\n* 浏览器验证证书合法性，并结合证书公钥加密信息发送给服务器\n\n* 服务器使用私钥解密信息，验证哈希，加密响应消息回发浏览器\n\n* 浏览器解密响应消息，并对消息进行验真，之后进行加密交互数据\n\n**它们根本的区别**\n\n* HTTPS需要到CA申请证书，HTTP不需要\n\n* HTTPS密文传输，HTTP明文传输\n\n* 连接方式不同，HTTPS默认使用443端口，HTTP使用80端口\n\n* HTTPS=HTTP+加密\n\n# Socket\n\nSocket是对TCP/IP协议的抽象，是操作系统对外开放的接口\n\n![](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529205902.png)\n\n**Socket是基于一种从打开到读和写再到关闭的这种模式去实现的，服务器和客户端各自维护一个文件再建立连接打开后，可以向自己文件写入内容供对方读取，或者读取对方内容，再通信结束时，就会关闭文件。**\n\n![Socket通信流程](http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190529210227.png)\n\n##关于SOCKET的一道面试题\n\n**编写一个网络应用程序，有客户端与服务器端，客户端向服务器发送一个字符串，服务器收到该字符串后将其打印到命令行上，然后向客户端返回该字符串的长度，最后，客户端输出服务器端返回的该字符串的长度，分别用TCP和UDP两种方法去实现**\n\n**TCP实现具体代码如下**\n\n**TCP Server(服务器)**\n\n```\nimport java.net.ServerSocket;\nimport java.net.Socket;\n\npublic class TCPServer {\n    public static void main(String[] args) throws Exception{\n        // 创建socket，并将socket绑定到65000端口\n        ServerSocket ss = new ServerSocket(65000);\n        // 死循环，使得socket一直等待并处理客户端发送过来的请求\n        while(true){\n            // 监听65000端口，知道客户端返回连接信息才返回\n            Socket socket = ss.accept();\n            // 获取客户端的请求信息后，执行相关业务逻辑\n            new LengthCalculator(socket).start();\n        }\n    }\n}\n\n```\n**LengthCalculator**\n\n```\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.net.Socket;\npublic class LengthCalculator extends Thread{\n    // 以socket为成员变量\n    private final Socket socket;\n\n    public LengthCalculator(Socket socket) {\n\n        this.socket = socket;\n    }\n    @Override\n    public void run(){\n        try {\n            // 获取socket的输出流\n            OutputStream os = socket.getOutputStream();\n            // 获取socket的输入流\n            InputStream is = socket.getInputStream();\n            int ch = 0 ;\n            byte[] buff = new byte[1024];\n            // buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度\n            ch = is.read(buff);\n            // 将接收流的byte数组转换成字符串，这里获取的内容是客户端发过来的字符串参数\n            String content = new String(buff,0,ch);\n            System.err.println(content);\n            // 往输出流里写入获得的字符串的长度，并回发给客户端\n            os.write(String.valueOf(content.length()).getBytes());\n            // 这里不要忘了关闭输入输出流的socket\n            os.close();\n            is.close();\n            socket.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n```\n\n**TCP Client(客户端)**\n\n```\nimport jdk.internal.util.xml.impl.Input;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\npublic class TCPClient\n{\n    public static void main(String[] args)throws Exception{\n        // 创建socket，并制定连接的是本机的端口号为65000 的服务器socket\n        Socket socket = new Socket(\"10.1.149.66\",65000);\n        // 获取输出流\n        OutputStream os = socket.getOutputStream();\n        // 获取输入流\n        InputStream is = socket.getInputStream();\n        // 将要传递给server的字符串参数转换成byte数组，并将数组写入到输出流当中\n        os.write(new String(\"Hello world\").getBytes());\n        int ch = 0;\n        byte[] buff = new byte[1024];\n        //buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度\n        ch = is.read(buff);\n        // 将接收流的byte数组转换成字符串，这里是从服务端回发回来的字符串参数的长度\n        String content= new String(buff,0,ch);\n        System.out.println(content);\n        // 这里不要忘了关闭输入输出流的socket\n        is.close();\n        os.close();\n        socket.close();\n    }\n}\n\n```\n\n**UDP**\n\n**UDP Server**\n\n```\nimport java.net.DatagramPacket;\nimport java.net.DatagramSocket;\n\npublic class UDPServer {\n    public static void main(String[] args)throws Exception{\n            // 服务端接收客户端发送的数据包\n            DatagramSocket socket = new DatagramSocket(65001);//监听端口号\n            // 存储从客户端接收到的内容\n            byte [] buff= new byte[100];\n            DatagramPacket packet = new DatagramPacket(buff,buff.length);\n            // 接收客户端发过来的内容，并将内容封装进DatagramPacket对象中\n            socket.receive(packet);\n            // 从DatagramPacket对象中获取到真正存储的数据\n            byte[] data = packet.getData();\n            // 将数据从二进制转换成字符串形式\n            String content = new String(data,0,packet.getLength());\n            System.err.println(content);\n            // 将要发送给客户端的数据转换成二进制\n            byte[] sendedContent = String.valueOf(content.length()).getBytes();\n            // 服务端给客户端发送数据报\n            // 从DatagramPacket对象中获取到数据的来源地址与端口号\n            DatagramPacket packetToclient = new DatagramPacket(sendedContent,\n                    sendedContent.length,packet.getAddress(),packet.getPort());\n            socket.send(packetToclient);  // 发送数据给客户端\n    }\n}\n\n```\n\n**UDP Client**\n\n\n```\nimport java.net.DatagramPacket;\nimport java.net.DatagramSocket;\nimport java.net.InetAddress;\n\npublic class UDPClient {\n    public static void main(String[] args) throws Exception{\n        // 客户端发数据报给服务端\n        DatagramSocket socket =new DatagramSocket();\n        // 要发给服务端的数据\n        byte[] buf = \"Hello World\".getBytes();\n        // 将IP地址封装成InetAddress对象\n        InetAddress address = InetAddress.getByName(\"10.1.149.66\");\n        // 将要发送给服务端的数据封装成DatagramPacket对象，需要填写上IP地址与端口号\n        DatagramPacket packet = new DatagramPacket(buf, buf.length, address, 65001);\n        //发送数据给服务端\n        socket.send(packet);\n\n        //客户端接收服务端发过来的数据报\n        byte[] data = new byte[100];\n        // 创建DatagramPacket对象用来存储服务端发过来的数据\n        DatagramPacket receivedPacket = new DatagramPacket(data,data.length);\n        // 将接收到的数据存储到DatagramPacket对象中\n        socket.receive(receivedPacket);\n        // 将服务器端发送过来的数据取出来并打印到控制台\n        String content = new String(receivedPacket.getData(),0,receivedPacket.getLength());\n        System.err.println(content);\n\n    }\n}\n\n\n```\n\n>小伙伴们想知道最后的结果自己亲身动手打一下代码就知道其中的原理喽。","tags":["学习笔记","网络"]},{"title":"基于Hadoop的数据仓库Hive安装","url":"/2019/05/16/基于Hadoop的数据仓库Hive安装/","content":"\n前面的博客，我们已经安装好了Hadoop，对于Hadoop的也有了比较深的了解。下面是我对数据仓库Hive的安装\n\n## 一、安装Hive\n\n**Hive的下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz**\n\n由于我下载的这个版本，所以我给的链接是这个版本的\n\n```\nsudo tar -zxvf ./apache-hive-1.2.1-bin.tar.gz -C /usr/local   # 解压到/usr/local中\ncd /usr/local/\nsudo mv apache-hive-1.2.1-bin hive       # 将文件夹名改为hive\nsudo chown -R hadoop:hadoop hive            # 修改文件权限\n```\n\n>注意，上面的hadoop：hadoop是用户组和用户名\n\n### 配置环境变量\n\n为了方便使用，我们把hive命令加入到环境变量中去，\n\n请使用gedit编辑器打开/etc/profile文件，命令如下：\n\n```\nsudo gedit /etc/profile\n```\n\n在文件最后一行加入下面内容：\n```\nexport HIVE_HOME=/usr/local/hive \nexport PATH=$PATH:$HIVE_HOME/bin \n```\n\n这里还需要HADOOP_HOME因为在上一篇或者以前你已经配好了，那就不用再写了\n\n在打开一个终端运行下面命令\n```\nsu \nsource /etc/profile\n```\n\n### 修改/usr/local/hive/conf下的hive-site.xml\n\n执行如下命令：\n\n```\ncd /usr/local/hive/conf\nmv hive-default.xml.template hive-default.xml\n```\n\n上面命令是将hive-default.xml.template重命名为hive-default.xml；\n\n然后，使用gedit编辑器新建一个配置文件hive-site.xml，命令如下：\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>javax.jdo.option.ConnectionURL</name>\n    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>\n    <description>JDBC connect string for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionDriverName</name>\n    <value>com.mysql.jdbc.Driver</value>\n    <description>Driver class name for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionUserName</name>\n    <value>hive</value>\n    <description>username to use against metastore database</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionPassword</name>\n    <value>hive</value>\n    <description>password to use against metastore database</description>\n  </property>\n</configuration>\n```\n>注意：这里一定不要写错了，如果写错了一个字，后面会出很大的问题，查找起来特别麻烦，就像C语言指针错了一样。很烦\n\n\n## 二、安装并配置mysql\n\n**这里我认为是最麻烦的，因为容易安装失败，安装失败后，一定要卸载干净再下载**\n\n**可能大家在Windows安装mysql有心态炸的时候吧，还记得那四个对号。我记得我当初心态炸了**\n\n这里我们采用MySQL数据库保存Hive的元数据，而不是采用Hive自带的derby来存储元数据。\n\nubuntu上安装mysql非常简单只需要几条命令就可以完成。\n\n```\nsudo apt-get install mysql-server\nsudo apt-get install mysql-client\nsudo apt-get install libmysqlclient-dev\n```\n\n安装过程中会提示设置密码什么的，注意设置了不要忘了，安装完成之后可以使用如下命令来检查是否安装成功：\n\n```\nsudo netstat -tap | grep mysql\n```\n\n通过上述命令检查之后，如果看到有mysql 的socket处于 listen 状态则表示安装成功。\n \n登陆mysql数据库可以通过如下命令：\n\n```\nmysql -u root -p \n```\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190516183158.png\"/>\n\n如果出现如上突脸看到mysql 的socket处于 listen 状态则表示安装成功。\n\n登陆mysql数据库可以通过如下命令：\n```\nmysql -u root -p \n```\n-u 表示选择登陆的用户名， -p 表示登陆的用户密码，上面命令输入之后会提示输入密码，此时输入密码就可以登录到mysql。\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190516183347.png\" />\n\n最后出现这个证明你完全没有问题了\n\n### 下面配置mysql的jdbc\n\n**mysql jdbc的包下载地址：https://dev.mysql.com/downloads/connector/j/\n\n或者通过别的渠道，我这里下载的5.1.4版本的\n\n下载后运行如下命令\n```\ntar -zxvf mysql-connector-java-5.1.40.tar.gz   #解压\ncp mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar  /usr/local/hive/lib #将mysql-connector-java-5.1.40-bin.jar拷贝到/usr/local/hive/lib目录下\n```\n\n### 启动并登陆mysql shell\n\n```\nservice mysql start #启动mysql服务\nmysql -u root -p  #登陆shell界面\n```\n\n### 新建hive数据库\n```\nmysql> create database hive;    #这个hive数据库与hive-site.xml中localhost:3306/hive的hive对应，用来保存hive元数据\n```\n>注意：在运行mysql和以后运行hive命令，一定不要忘了后面加；号，要不命令是不会生效的，系统默认还没有完成命令的编写。\n\n### 配置mysql允许hive接入：\n\n```\nmysql> grant all on *.* to hive@localhost identified by 'hive';   #将所有数据库的所有表的所有权限赋给hive用户，后面的hive是配置hive-site.xml中配置的连接密码\nmysql> flush privileges;  #刷新mysql系统权限关系表\n```\n\n## 启动hive\n\n启动hive之前，先启动hadoop集群\n\n```\nstart-all.sh #启动hadoop\n```\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190516184518.png\"  />\n\n如果出现上面图出现6个，那说明启动成功了，如果不成功，看那个没出来去网上查找解决方案\n\n然后启动hive\n```\nhive  #启动hive\n```\n\n>注意，我们这里已经配置了PATH，所以，不要把start-all.sh和hive命令的路径加上。如果没有配置PATH，请加上路径才能运行命令，比如，本教程Hadoop安装目录是“/usr/local/hadoop”，Hive的安装目录是“/usr/local/hive”，因此，启动hadoop和hive，也可以使用下面带路径的方式：\n\n```\ncd /usr/local/hadoop\n./sbin/start-all.sh\ncd /usr/local/hive\n./bin/hive\n```\n\n如果出现如下错误\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190516200558.png\"  />\n\n则需要进入到hadoop安装目录下的share/hadoop/yarn/lib下删除jline-0.9.94.jar文件，再启动hive即可（因为高版本的Hadoop对Hive有捆绑）。\n\n如果出现，这里我一直在处理问题，我忘了截图了，就是出现(jdbc-type=\"\", sql-type=\"\") 这种的错误，是因为jdk的版本过高，造成编译过程中出现了问题\n\n```\n Datastore.Schema (Log4JLogger.java:error(125)) - Failed initialising database.\nThe java type java.lang.Integer (jdbc-type=\"\", sql-type=\"\") cant be mapped for this datastore. No mapping is available.\norg.datanucleus.exceptions.NucleusException: The java type java.lang.Integer (jdbc-type=\"\", sql-type=\"\") cant be mapped for this datastore. No mapping is available.\n\n```\n**特别注意！！！：这里由于我使用的12版本的JKD出现的问题，查找了好久，最后降了版本使用了1.8的就好使了，以后不管干什么不要用高版本的，记住高版本兼容低版本，而低版本用不了高版本！一定要记住不管干什么，要不然查找问题起来特别的麻烦，我也修改了上个博客。**\n\n最后在运行hive\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190516200943.png\"  />\n\n那么你成功了！恭喜你！\n\n可以在里面输入SQL语句，如果要退出Hive交互式执行环境，可以输入如下命令：\n\n```\nhive>exit;\n```\n\n**这里还要注意一点：**\n\n**启动完hive后，启动另外的中段运行jps，看看ResourceManager有没有死掉，如果死掉了。对于后面Hive的使用会出问题。**\n\n**简单介绍下ResourceManager**\n\n**ResourceManager (RM)是仲裁所有可用集群资源的主程序，从而帮助管理在纱线系统上运行的分布式应用程序。它与每个节点的节点管理器(NMs)和每个应用程序的应用程序管理器(AMs)一起工作。**\n\n## 推荐\n\n如果你有英语的一定基础，或者你可以看懂英文的文档推荐一个网站https://zh.hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/\n\n这个网站介绍了ResourceManager，你也可以查找相关的文档，英文的文档我认为更加的细致。\n\n如果你Java的变成能力特别好，推荐你看Hadoop的底层源码。\n\n\n\n\n## 参考\n\n【林子雨编写的《大数据 基础编程、实验和案例教程》】\n\n\n\n\n\n\n\n\t\n\t\n","tags":["Hadoop","Hive","数据仓库"]},{"title":"Hadoop伪分布式集群的搭建","url":"/2019/05/15/Hadoop伪分布式集群的搭建/","content":"我在后面学习Hive的时候，在最开始我的Hadoop集群搭建的有问题，所以我决定重头搭建，然后做出笔记。写了一些自己遇到的坑，这里来把这些坑给填上。\n\nHadoop基本安装配置主要包括以下5个步骤。\n（1）创建Hadoop用户\n（2）安装Java\n（3）设置SSH登录权限\n（4）单机安装配置\n（5）伪分布式安装配置\n我使用的操作系统是Ubuntu14.4，Hadoop版本为2.7.3\n\n## 第一步，先安装一个Linux系统，创建Hadoop用户\n我用的是VMware虚拟机，我大学生涯就用了这一个虚拟机，感觉短小精悍功能强大。\n我选择的是Ubuntu系统，因为我感觉Ubuntu的系统用起来比较舒服，并且遇到问题在网络上写Ubuntu的解决方案也比较多，推荐使用Ubuntu。\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515175725.png\"  />\n\n这里我就完成了第一步的操作\n在创建虚拟机的过程中我就建立了一个Hadoop用户，为了规范，在使用Linux系统对于用户比较敏感，因为Linux是多用户的。尽量养成一种好的习惯，名字为Hadoop用户那么这个用户就是关于Hadoop的。\n\n## 第二步，安装Java\n我以为是新装的Ubuntu不能连接FileZilla，需要下载ssh\n\n安装ssh\n```\nsudo apt-get install openssh-server\n```\n\n安装完后查看ssh server是否启动\n```\nsudo /etc/init.d/ssh status\n```\n\n如果没有启动，使用一下命令启动：\n```\nsudo /etc/init.d/ssh start\n```\n\n根据ifconfig查看IP，用FileZilla连接，使用非常简单一看就会。\n网上下载一个JDK-linux版本的\n\n这里遇到了一个坑，一定要注意和自己Linux位数相同的看好自己的是32位还是64位，我下的12.0.1版本的JDK\n\n>这里一定不要下高版本的JDK，我在后面的Hive数据仓库安装的时候出现了问题，最后我改成改了1.8版本的。\n\n```\nsudo uname --m\n```\n\n之后就是JDK的配置问题，网络有有好多的配置方法可以参考\n\n>特别注意：在配置环境变量的时候\nsudo gedit ~/.bashrc #这里配置是给当前用户配置的环境变量，如果用的prefile配置则不考虑用户的问题，特别注意\n\n## 第三步，SSH登录权限设置，设置无密码登录\n\n```\n$ sudo apt-get install openssh-server   #安装SSH server\n$ ssh localhost                         #登陆SSH，第一次登陆输入yes\n$ exit                                  #退出登录的ssh localhost\n$ cd ~/.ssh/                            #如果没法进入该目录，执行一次ssh localhost\n$ ssh-keygen -t rsa　　\n```\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515203918.png\"/>\n\n\n其中，第一次回车是让KEY存于默认位置，以方便后续的命令输入。第二次和第三次是确定passphrase，相关性不大。两次回车输入完毕以后，如果出现类似于下图所示的输出，即成功：\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515203954.png\"  />\n\n\n之后再输入\n```\n$ cat ./id_rsa.pub >> ./authorized_keys #加入授权\n$ ssh localhost                         #此时已不需密码即可登录localhost\n```\n## 第四步，单机安装Hadoop\n\n**我安装的Hadoop版本为2.7.3，下载地址为http://hadoop.apache.org/releases.html#Download**\n\n在目录中选择hadoop-2.7.3.tar.gz进行下载就行了\n\n我是放在了/usr/local/haddoop文件夹下，注意这里一定要改这个文件夹的权限\n```\nsudo chown -R hadoop ./hadoop                        #修改文件权限\n```\n\n然后给hadoop配置环境变量，在当前用户下配置\n```\ngedit ~/.bashrc\n```\n\n添加如下代码：\n```\nexport HADOOP_HOME=/usr/local/hadoop/hadoop-2.7.3  #这里的路径为你安装hadoop的文件夹\nexport CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n```\n>注意：一定要看好自己装的文件夹，别把Hadoop的上级文件放上去。就是在这个目录下一级是如下图所示：\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515205305.png\"  />\n\n\n在使用source ~/.bashrc命令出现如下图，证明你迈出了第一步，安装好了Hadoop但是没有集群的搭建，不要放弃，也不要觉得配置完了\n接下来才是更大的难题，更容易出错的地方\nhttp:// prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515205548.png\n\n## 第五步，Hadoop伪分布式安装\n\nHadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。首先将jdk1.7的路径添（export JAVA_HOME=/usr/lib/jvm/java ）加到hadoop-env.sh文件 \n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515211148.png\"  />\n\n配置hadoop-env.sh文件，在hadoop安装目录下的/etc/hadoop/\n```\ngedit hadoop-env.sh\n```\n\n修改第27行\n\n```\nexport JAVA_HOME=你的JDK路径\n```\n\n接下来修改core-site.xml文件:\n```\n<configuration>\n <name>hadoop.tmp.dir</name>\n             <value>file:/usr/local/hadoop/hadoop-2.7.3/tmp</value>\n             <description>Abase for other temporary directories.</description>\n        </property>\n        <property>\n             <name>fs.defaultFS</name>\n             <value>hdfs://localhost:9000</value>\n        </property>\n</configuration>\n```\n>还要特别注意这里面的路径都要写你安装hadoop的路径，千万别错了。后面出问题找很麻烦\n>这里要注意要创建一个tmp的文件夹，防止以后有问题出现\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515211448.png\"  />\n\n\n然后配置hdfs-site.xml文件\n```\n<configuration>\n<property>\n             <name>dfs.replication</name>\n             <value>1</value>\n        </property>\n        <property>\n             <name>dfs.namenode.name.dir</name>\n             <value>file:/usr/local/hadoop/hadoop-2.7.3/tmp/dfs/name</value>\n        </property>\n        <property>\n             <name>dfs.datanode.data.dir</name>\n             <value>file:/usr/local/hadoop/hadoop-2.7.3/tmp/dfs/data</value>\n        </property>\n</configuration>\n```\n\n>注意：这里的路径也是安装路径\n\nHadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（可参考官方教程），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。\n\n配置完成后，执行 NameNode 的格式化\n```\n./bin/hdfs namenode -format\n```\n\n如果出现bash: ./bin/hdfs: No such file or directory\n\n则可以去你Hadoop安装目录下的bin目录运行，是一样的\n\n```\nhdfs namenode -format\n```\n\n最后出现如下图，那么证明成功了\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515212307.png\"  />\n\n\n启动namenode和datanode进程，并查看启动结果\n\n```\n./sbin/start-dfs.sh\njps\n```\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515223447.png\"  />\n\n\n然后停止\n\n```\n./sbin/stop-dfs.sh\njps\n```\n\n看看全启动是否成功，运行下面命令\n\n```\nstart-all.sh\njps\n```\n**如果出现下面的图就说明你安装成功了 恭喜你！！！**\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515223929.png\"  />\n\n\n成功启动后，可以访问 Web 界面 http://localhost:50070 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。\n\n<img src=\"http://prj1hj366.bkt.clouddn.com/qiniu_picGO/20190515224126.png\"  />\n\n## 参考\n\n【更多的细节可以参照https://www.cnblogs.com/87hbteo/p/7606012.html 感谢大佬】\n\n【还有林子雨编写的《大数据技术 原理与应用》】\n\n\n\n\n\n\n\n\t\n\t\n","tags":["Hadoop","Ubuntu","分布式"]}]